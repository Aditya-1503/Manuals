{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql.functions import sum as spark_sum, avg as spark_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame([('201','10/13/2017', '100', 'NY', '131', '100.00'), \n",
    " ('204', '10/18/2017', '700', 'TX', '129', '450.00'),\n",
    " ('202', '10/15/2017', '203', 'CA', '121', '200.00'),\n",
    " ('206', '10/19/2017', '202', 'CA', '131', '500.00'),\n",
    " ('203', '10/17/2017', '101', 'NY', '173', '750.00'),\n",
    " ('205', '10/19/2017', '202', 'TX', '121', '200.00'),\n",
    " ('203', '10/17/2017', '101', 'NY', '173', '50.00')], ('Id string, Timestamp string, Customer string, State string, ServiceID string, Amount string'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------+-----+---------+------+\n",
      "| Id| Timestamp|Customer|State|ServiceID|Amount|\n",
      "+---+----------+--------+-----+---------+------+\n",
      "|201|10/13/2017|     100|   NY|      131|100.00|\n",
      "|204|10/18/2017|     700|   TX|      129|450.00|\n",
      "|202|10/15/2017|     203|   CA|      121|200.00|\n",
      "|206|10/19/2017|     202|   CA|      131|500.00|\n",
      "|203|10/17/2017|     101|   NY|      173|750.00|\n",
      "|205|10/19/2017|     202|   TX|      121|200.00|\n",
      "|203|10/17/2017|     101|   NY|      173| 50.00|\n",
      "+---+----------+--------+-----+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df.filter(df.Id > 201)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------+-----+---------+------+\n",
      "| Id| Timestamp|Customer|State|ServiceID|Amount|\n",
      "+---+----------+--------+-----+---------+------+\n",
      "|204|10/18/2017|     700|   TX|      129|450.00|\n",
      "|202|10/15/2017|     203|   CA|      121|200.00|\n",
      "|206|10/19/2017|     202|   CA|      131|500.00|\n",
      "|203|10/17/2017|     101|   NY|      173|750.00|\n",
      "|205|10/19/2017|     202|   TX|      121|200.00|\n",
      "|203|10/17/2017|     101|   NY|      173| 50.00|\n",
      "+---+----------+--------+-----+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtered_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------+-----+---------+------+------+\n",
      "| Id| Timestamp|Customer|State|ServiceID|Amount|Salary|\n",
      "+---+----------+--------+-----+---------+------+------+\n",
      "|201|10/13/2017|     100|   NY|      131|100.00| 340.0|\n",
      "|204|10/18/2017|     700|   TX|      129|450.00|1530.0|\n",
      "|202|10/15/2017|     203|   CA|      121|200.00| 680.0|\n",
      "|206|10/19/2017|     202|   CA|      131|500.00|1700.0|\n",
      "|203|10/17/2017|     101|   NY|      173|750.00|2550.0|\n",
      "|205|10/19/2017|     202|   TX|      121|200.00| 680.0|\n",
      "|203|10/17/2017|     101|   NY|      173| 50.00| 170.0|\n",
      "+---+----------+--------+-----+---------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn('Salary', col('Amount').cast('float')*3.4).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_count = df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "salarySum = df.select(spark_sum(df.Amount)).collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2250.0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salarySum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaryAvg = df.select(spark_avg(df.Amount)).collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "321.42857142857144"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salaryAvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.csv('sample.csv', header='False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---+---+---+------+\n",
      "|_c0|       _c1|_c2|_c3|_c4|   _c5|\n",
      "+---+----------+---+---+---+------+\n",
      "|206|10/19/2017|202| CA|131|500.00|\n",
      "|204|10/18/2017|700| TX|129|450.00|\n",
      "|201|10/13/2017|100| NY|131|100.00|\n",
      "|202|10/15/2017|203| CA|121|200.00|\n",
      "|205|10/19/2017|202| TX|121|200.00|\n",
      "|203|10/17/2017|101| NY|173|750.00|\n",
      "|203|10/17/2017|101| NY|173| 50.00|\n",
      "+---+----------+---+---+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.csv('sample.csv', header=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
