{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f68b0f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f44a7935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentence \"A very close game\" is classified as: 'Sports'\n"
     ]
    }
   ],
   "source": [
    "class NaiveBayesTextClassifier:\n",
    "    def __init__(self):\n",
    "        self.class_probs = {}\n",
    "        self.word_probs = {}\n",
    "        self.vocabulary = set()\n",
    "        self.classes = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes = y.unique()\n",
    "        \n",
    "        # Calculate class probabilities\n",
    "        class_counts = y.value_counts()\n",
    "        total_count = len(y)\n",
    "        self.class_probs = {cls: count / total_count for cls, count in class_counts.items()}\n",
    "        \n",
    "        # Initialize word probabilities\n",
    "        self.word_probs = {cls: {} for cls in self.classes}\n",
    "        self.vocabulary = set()\n",
    "        \n",
    "        for cls in self.classes:\n",
    "            subset = X[y == cls]\n",
    "            words = ' '.join(subset).split()\n",
    "            self.vocabulary.update(words)\n",
    "            word_counts = pd.Series(words).value_counts()\n",
    "            total_words = len(words)\n",
    "            for word in self.vocabulary:\n",
    "                # Applying Laplace smoothing\n",
    "                self.word_probs[cls][word] = (word_counts.get(word, 0) + 1) / (total_words + len(self.vocabulary))\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for text in X:\n",
    "            words = text.split()\n",
    "            class_probs = {}\n",
    "            for cls in self.classes:\n",
    "                prob = self.class_probs[cls]\n",
    "                for word in words:\n",
    "                    prob *= self.word_probs[cls].get(word, 1 / (sum(self.word_probs[cls].values()) + len(self.vocabulary)))\n",
    "                class_probs[cls] = prob\n",
    "            predicted_class = max(class_probs, key=class_probs.get)\n",
    "            predictions.append(predicted_class)\n",
    "        return predictions\n",
    "\n",
    "df = pd.read_csv('Lab7_2.csv')\n",
    "\n",
    "# Train the classifier\n",
    "nb_classifier = NaiveBayesTextClassifier()\n",
    "nb_classifier.fit(df['Text'], df['Tag'])\n",
    "\n",
    "# Predict on the entire dataset (since we are not splitting into train/test)\n",
    "y_true = df['Tag']\n",
    "y_pred = nb_classifier.predict(df['Text'])\n",
    "# print(y_pred)\n",
    "\n",
    "\n",
    "# # Predict the class for a new sentence\n",
    "test_sentence = [\"A very close game\"]\n",
    "predicted_tag = nb_classifier.predict(test_sentence)\n",
    "# print(predicted_tag)\n",
    "print(f'The sentence \"A very close game\" is classified as: {predicted_tag[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f57ea44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
